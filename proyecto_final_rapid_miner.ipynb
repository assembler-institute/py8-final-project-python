{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fa77505",
   "metadata": {},
   "source": [
    "# Proyecto final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f9d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_data(file):\n",
    "    # We open the file as read and return all the lines of the file as a list of strings\n",
    "    with open(file,'r') as data:\n",
    "        c_total=c_blank=c_lines=c_comm=c_comas=0  \n",
    "        symbols='\"!@#$%^&*()-+?_=,<>/\"'\n",
    "        lines = data.readlines()\n",
    "        c_total=len(lines)\n",
    "\n",
    "        print(f'The file has {c_total} lines.')\n",
    "        #print(lines)\n",
    "\n",
    "        for line in lines:\n",
    "            if line==\"\\n\":  \n",
    "                c_blank+=1\n",
    "            elif line[0] in symbols:  \n",
    "                c_comm+=1\n",
    "            else:\n",
    "                for char in line:\n",
    "                    #this is to double-check that the data lines have 2 commas each one. We found out that the number\n",
    "                    #of commas ar double times the data lines we calculated before.\n",
    "                    if char ==',':                 \n",
    "                        c_comas+=1\n",
    "\n",
    "        c_lines=c_total-c_blank-c_comm\n",
    "\n",
    "        print(f'The number of blank lines are {c_blank}') \n",
    "        print(f'The number of comments lines are {c_comm}') \n",
    "        print(f'The number of data lines are {c_lines}')\n",
    "        print(f'The number of comas are {c_comas}')\n",
    "        \n",
    "        if c_comas!=c_lines*2:\n",
    "            print(f'EHHHHHH they are lines whitout comas or more than 2 comas')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934bf040",
   "metadata": {},
   "source": [
    "In this function called read_and_clean we create a list called list_line where we put all the lines with commas that are the data lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5583dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_clean(file, characters_for_comments='\"!@#$%^&*()-+?_=,<>/\"'):\n",
    "    with open(file,'r') as data:\n",
    "        lines = data.readlines()\n",
    "        list_lines=[] \n",
    "        for line in lines:\n",
    "            if line!=\"\\n\" and (line[0] not in characters_for_comments):  \n",
    "                line = line[:-1]\n",
    "                list_lines.append(line)\n",
    "        return list_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3814acf3",
   "metadata": {},
   "source": [
    "Now we have all the clean data in the list list_lines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc5c2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_lines=read_and_clean(\"Files/data.txt\",)\n",
    "print(\"\\n\",len(list_lines))\n",
    "print(list_lines[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0274611b",
   "metadata": {},
   "source": [
    "This function called features_picker_cleaner cleans the elements of the chosen feature and return them in a list called featureclean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8355d82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_picker_cleaner(entries,feature=1, leftover_chars='\"!@#$%^&*-+?_=<>/\" '):\n",
    "    featureclean=[]\n",
    "    #A high order function is used. It will map the list which is introduced in the argument,\n",
    "    #in our case list_lanes which is a list of 1970 strings. Here those strings will be splitted by the commas, \n",
    "    #and generate a list of small lists with 3 elements, which are the string type.\n",
    "    superlist=list(map(lambda x: x.split(',') , entries))\n",
    "    for minilist in superlist:\n",
    "       \n",
    "        if feature==1:\n",
    "            clean_name=minilist[0].strip(leftover_chars)\n",
    "            featureclean.append(clean_name)\n",
    "        elif feature==2:\n",
    "            clean_url=minilist[1].strip(leftover_chars)\n",
    "            featureclean.append(clean_url)\n",
    "        elif feature==3:\n",
    "            clean_desc=minilist[2].strip(leftover_chars)\n",
    "            featureclean.append(clean_desc)\n",
    "        else:\n",
    "            print(\"That's is not a FEATURE\") \n",
    "        \n",
    "    return featureclean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44600fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter(value_to_search, where_to_look_for):\n",
    "    count_values=list(map(lambda x:x.count(value_to_search),where_to_look_for))\n",
    "    return sum(count_values)\n",
    "\n",
    "    # return sum(list(map(lambda x:x.count(value_to_search),where_to_look_for))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2f9219",
   "metadata": {},
   "source": [
    "We want to create a dictionary. The keys will be the elements contained in the list of a given feature, and the values will be the number of times that appear in the list. This list of the feature will be the one we cleaned previously. As it was specified, we used the counter function we created previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef417a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def values_and_frequencies(where_to_look_for,min_num_repetitions):\n",
    "    list_of_low_frec=[]\n",
    "    dictionary_of_frecuencies={}\n",
    "    #with this loop we go through the cleaned feature list (names for example) and call the counter \n",
    "    #function to tell how many times that name appears in the list.    \n",
    "    for name in where_to_look_for:\n",
    "        count=counter(name,where_to_look_for)\n",
    "        #each name will be added to a dictionary, and the ones repeated will be substituted.\n",
    "        dictionary_of_frecuencies.update({name:count})\n",
    "        #we go trough each pair of key and values given in a tuple, and if number \n",
    "        #of repetitions don't match the condition, we append the key in a list we will use after.\n",
    "    \n",
    "    for k,v in dictionary_of_frecuencies.items():\n",
    "        \n",
    "        if v <=min_num_repetitions:\n",
    "            list_of_low_frec.append(k)\n",
    "      #we use that list to  remove all those pairs k:v from the dictionary as they don't meet the \n",
    "    #condition  \n",
    "    for key in list_of_low_frec:    \n",
    "        del dictionary_of_frecuencies[key]\n",
    "    return dictionary_of_frecuencies  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c00bd81",
   "metadata": {},
   "source": [
    "A function called filter_names is created in order to ,firtly, obtain a desired feature already cleaned, sorted alphabetically, and write it in a file with the second half removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7316273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_names(list_1):\n",
    "    #the feature is picked and instanced once cleaned.\n",
    "    featureclean_name=features_picker_cleaner(list_1,1, leftover_chars='\"!@#$%^&*-+?_=<>/\". ')\n",
    "    sorted_name=sorted(featureclean_name)\n",
    "    #a file is created, and the first half is written in it already sorted    \n",
    "    with open('Files/patients_names.txt', \"w\", encoding='utf-8') as file:\n",
    "        dim=int(len(list_1)/2)\n",
    "        file.writelines([f\"{name}\\n\" for name in sorted_name[dim]])\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887aa8de",
   "metadata": {},
   "source": [
    "This function transforms the list of urls into a set to extract all the repeating domains and then cleans it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe6d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_extraction(list_1):\n",
    "    featureclean_url=set(features_picker_cleaner(list_1,2))\n",
    "    print(f\"Total lines:{len(list_lines)} Unique Lines:{len(featureclean_url)}\")\n",
    "    \n",
    "    #this is another way to find out how many different urls there are in the list, using the \n",
    "    #values_and_frecuency function (when creating a dictionary, the repeated ones are remplaced).\n",
    "  \n",
    "   \n",
    "    return list(featureclean_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc700419",
   "metadata": {},
   "source": [
    "This function called characteristics_organizations cleans the list of descriptions (list_desc), then calls the function values_and_frequencies that creates a dictionary with the description as keys, and their frecuency as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6a8ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def characteristics_organization(list_1):\n",
    "     #as before, a list of lists is instanced in superlist.\n",
    "    superlist=list(map(lambda x: x.split(',') , list_1))\n",
    "    list_desc=[]\n",
    "    #the lists contained in the superlist are went through a loop so that the description \n",
    "    #feature is cleaned and if not empty, appended to a list called list_desc.\n",
    "    for minilist in superlist:\n",
    "            desc_clean=minilist[2].strip('\"!@#$%^&*-+?_=<>/\". ')\n",
    "\n",
    "            if desc_clean !=\"\":\n",
    "                list_desc.append(desc_clean)\n",
    "     #The list_desc list is used as an argument when called the values_and_frequencies function, in order to \n",
    "    #obtain a dictionary with the description as keys, and their frecuency as values.\n",
    "    dicc_descp_frecuen=values_and_frequencies(list_desc,1)\n",
    "    print(f\"{dicc_descp_frecuen}/n\")\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2e4ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "initial_data(\"Files/data.txt\")\n",
    "print()\n",
    "\n",
    "\n",
    "feature_value=int(input(\"Which feature you want to clean? (1:name;2:url;3:descriptor): \"))\n",
    "value_count=input(\"What string do you want to COUNT?: \")\n",
    "num_frec=int(input(\"How many minimum repetitions?\"))\n",
    "\n",
    "list_lines=read_and_clean(\"Files/data.txt\",)\n",
    "\n",
    "featureclean=features_picker_cleaner(list_lines,feature_value)\n",
    "\n",
    "quanties=counter(value_count,featureclean)\n",
    "\n",
    "dict_of_frecuencies=values_and_frequencies(featureclean,num_frec)\n",
    "\n",
    "\n",
    "print(f\"read_and_clean solution:\\n{list_lines[30:40]}\\n\\n features_picker_cleane solution:\\n{featureclean[30:40]}\\n\\n counter solution :{quanties,value_count}\\n\\n values_and_frequencies solution:\\n{dict_of_frecuencies}\\n\")\n",
    "\n",
    "filter_names(list_lines)\n",
    "print(domain_extraction(list_lines)[:10])\n",
    "print()\n",
    "characteristics_organization(list_lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
